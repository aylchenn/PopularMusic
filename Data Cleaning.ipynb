{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('raw_music.csv')\n",
    "\n",
    "new_musc1 = raw[raw['year']>=1950][['artist.name','artist.hotttnesss', 'title','year',\n",
    "        'bars_confidence', 'bars_start',\n",
    "       'beats_confidence', 'beats_start', 'duration', 'end_of_fade_in',\n",
    "       'familiarity', 'key', 'key_confidence', 'latitude', 'location',\n",
    "       'longitude', 'loudness', 'mode', 'mode_confidence', 'release.id',\n",
    "       'release.name', 'similar', 'song.hotttnesss', \n",
    "       'start_of_fade_out', 'tatums_confidence', 'tatums_start', 'tempo',\n",
    "       'terms', 'terms_freq', 'time_signature', 'time_signature_confidence']]\n",
    "\n",
    "\n",
    "new_musc1.columns = ['artist.name','artist.hotness', 'Songs','Year',\n",
    "        'bars_confidence', 'bars_start',\n",
    "       'beats_confidence', 'beats_start', 'duration', 'end_of_fade_in',\n",
    "       'familiarity', 'key', 'key_confidence', 'latitude', 'location',\n",
    "       'longitude', 'loudness', 'mode', 'mode_confidence', 'release.id',\n",
    "       'release.name', 'similar', 'song.hotness', \n",
    "       'start_of_fade_out', 'tatums_confidence', 'tatums_start', 'tempo',\n",
    "       'terms', 'terms_freq', 'time_signature', 'time_signature_confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_musc1['Decade']= pd.cut(new_musc1['Year'],[1949,1959,1969,1979,1989,1999,2009,np.inf],labels=['50s','60s','70s','80s','90s','00s','10s'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music1.to_csv('music_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = pd.read_csv('../music_cleaned_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music= music[music['song.hotness']!=0]\n",
    "music['artists.grouped']= pd.cut(music['artist.hotness'],[-np.inf,0.3,0.65,np.inf],labels=['low','medium','high'])\n",
    "columns_keep = ['artist.name','artist.hotness', 'Songs','Year',\n",
    "        'duration', 'familiarity', 'key',  'location',\n",
    "       'loudness', 'mode', 'mode_confidence', \n",
    "       'start_of_fade_out','end_of_fade_in', 'grouped_terms', 'tempo',\n",
    "       'time_signature', 'time_signature_confidence','decade','artist.grouped','song.hotness']\n",
    "music = music[columns_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music.to_csv('final_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###the entire dataset has 10,000 rows; after dropping anything from 50s before, we have 4664.\n",
    "###of these, 1600+352 = 1952 rows has invalid song.hotness; 1618 has invalid location\n",
    "###if we drop na, the total would be 2710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../prepared1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4312 entries, 0 to 4311\n",
      "Data columns (total 22 columns):\n",
      "Unnamed: 0                   4312 non-null int64\n",
      "artist.name                  4312 non-null object\n",
      "artist.hotness               4312 non-null float64\n",
      "Songs                        4312 non-null object\n",
      "Year                         4312 non-null int64\n",
      "duration                     4312 non-null float64\n",
      "familiarity                  4312 non-null float64\n",
      "key                          4312 non-null int64\n",
      "city                         2542 non-null object\n",
      "state                        1946 non-null object\n",
      "country                      2847 non-null object\n",
      "Unnamed: 11                  0 non-null float64\n",
      "mode_confidence              4312 non-null float64\n",
      "start_of_fade_out            4312 non-null float64\n",
      "end_of_fade_in               4312 non-null float64\n",
      "grouped_terms                4312 non-null object\n",
      "tempo                        4312 non-null float64\n",
      "time_signature               4312 non-null int64\n",
      "time_signature_confidence    4312 non-null float64\n",
      "decade                       4312 non-null object\n",
      "artists.grouped              4312 non-null object\n",
      "song.hotness                 2712 non-null float64\n",
      "dtypes: float64(10), int64(4), object(8)\n",
      "memory usage: 741.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        nan\n",
       "1                                        nan\n",
       "2                                        nan\n",
       "3                                        nan\n",
       "4                                        nan\n",
       "5                                        nan\n",
       "6                                        nan\n",
       "7                                        nan\n",
       "8                                        nan\n",
       "9                           Nashville,TN,USA\n",
       "10                          Nashville,TN,USA\n",
       "11                        Los Angeles,CA,USA\n",
       "12                                       nan\n",
       "13                                       nan\n",
       "14                                       nan\n",
       "15                                       nan\n",
       "16                                       nan\n",
       "17                                       nan\n",
       "18                                       nan\n",
       "19                                       nan\n",
       "20                                       nan\n",
       "21                                       nan\n",
       "22                                       nan\n",
       "23                                       nan\n",
       "24                                       nan\n",
       "25                                       nan\n",
       "26                                       nan\n",
       "27                                       nan\n",
       "28                                       nan\n",
       "29                                       nan\n",
       "                        ...                 \n",
       "4282                            Lamar,CO,USA\n",
       "4283                      Port Arthur,TX,USA\n",
       "4284                           Ramsey,IL,USA\n",
       "4285         Hughesdale ,Victoria ,Australia\n",
       "4286                            Kosse,TX,USA\n",
       "4287                        Milwaukee,WI,USA\n",
       "4288                            Kosse,TX,USA\n",
       "4289    Hughesdale Victoria Australia,TX,USA\n",
       "4290                       Birmingham,AL,USA\n",
       "4291                          Paw Paw,WV,USA\n",
       "4292                          Paw Paw,WV,USA\n",
       "4293                            Rayne,LA,USA\n",
       "4294                            Kosse,TX,USA\n",
       "4295                          Paw Paw,WV,USA\n",
       "4296                      Brownsville,TX,USA\n",
       "4297                      Brownsville,TX,USA\n",
       "4298                                     nan\n",
       "4299                                     nan\n",
       "4300                                     nan\n",
       "4301                                     nan\n",
       "4302                                     nan\n",
       "4303                                     nan\n",
       "4304                                     nan\n",
       "4305                        Lafayette,LA,USA\n",
       "4306                                     nan\n",
       "4307                                     nan\n",
       "4308                        Lafayette,LA,USA\n",
       "4309                        Opelousas,LA,USA\n",
       "4310                                     nan\n",
       "4311                      Port Arthur,TX,USA\n",
       "Length: 4312, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LO = df['city']+\",\"+df['state']+','+df['country']\n",
    "#df[['city','state','country']]\n",
    "LO.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latlong(query,api_key='AIzaSyA7jvdNPehTrRCo_VZlyMZ7C0rjXaiAItM'):\n",
    "    import requests\n",
    "    import time\n",
    "    from time import sleep\n",
    "    api_url= \"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
    "    if type(query)==str:\n",
    "        #print(str(query))\n",
    "        #print(type(query))\n",
    "        api_url+= \"query=\" + query\n",
    "        api_url+= \"&key=\"+ api_key\n",
    "        response = requests.get(api_url).json()\n",
    "        #print(api_url)\n",
    "        #print(response)\n",
    "        if response['status']=='OK':\n",
    "            \n",
    "            loca = response['results'][0]['formatted_address']\n",
    "            lat = response['results'][0]['geometry']['location']['lat']\n",
    "            long = response['results'][0]['geometry']['location']['lng']\n",
    "            #print(loca,lat,long)\n",
    "            \n",
    "        else:\n",
    "            loca = None\n",
    "            lat = None\n",
    "            long = None\n",
    "        \n",
    "    else:\n",
    "        loca = None\n",
    "        lat = None\n",
    "        long = None\n",
    "    \n",
    "    return loca,lat,long\n",
    "            \n",
    "        \n",
    "\n",
    "#get_latlong('Port Arthur,TX,USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= LO.apply(get_latlong)\n",
    "df['location'], df['latitude'], df['longitude'] = zip(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('music_with_location.csv')\n",
    "\n",
    "import folium\n",
    "m = folium.Map(location=[40.8075,-73.9626],zoom_start=14)\n",
    "\n",
    "location_df = df[['location','latitude','longitude']]\n",
    "location_df=location_df.set_index('location')\n",
    "\n",
    "colordict = {0: 'lightblue', 1: 'lightgreen', 2: 'orange', 3: 'red'}\n",
    "#   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "#         14,  15,  16,  17,  19,  21,  22,  32,  34,  37,  38,  43,  55,\n",
    "#        148, 182\n",
    "mean_hotness = df.groupby('location')['artist.hotness'].mean()\n",
    "artist_count = df.groupby('location').size()\n",
    "#for lat, lon, loca in zip(df['latitude'], df['longitude'], df['location']):\n",
    "traffic_map = folium.Map(location=[40.7128, 74.006], zoom_start=5)\n",
    "for loca in df['location'].unique()[1:]:\n",
    "    \n",
    "    count = artist_count.loc[loca]\n",
    "    if count >1:\n",
    "        lat = location_df['latitude'].loc[loca].iloc[0]\n",
    "        lon = location_df['longitude'].loc[loca].iloc[0]\n",
    "    else:\n",
    "        lat = location_df['latitude'].loc[loca]\n",
    "        lon = location_df['longitude'].loc[loca]\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=.15*artist_count.loc[loca],\n",
    "        popup = ('Location: ' + loca + '<br>'\n",
    "                 'Count: ' + str(artist_count.loc[loca]) + '<br>'\n",
    "                 'Average Artist Hotness: ' + str(mean_hotness.loc[loca]) \n",
    "                ),\n",
    "#         color='b'\n",
    "#             key_on = traffic_q,\n",
    "#             threshold_scale=[0,1,2,3],\n",
    "#             fill_color=colordict[traffic_q],\n",
    "#             fill=True,\n",
    "#             fill_opacity=0.7\n",
    "        ).add_to(traffic_map)\n",
    "traffic_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R code from here on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music=read.csv('/Users/AriaChen/Desktop/Columbia/E4650 BA/Group Project/final_cleaned.csv')\n",
    "music = na.omit(music)\n",
    "attach(music)\n",
    "\n",
    "# split data into three classes according to artist hotness\n",
    "high_class = music[which(artist.hotness>=0.65),]\n",
    "medium_class = music[which(artist.hotness>=0.3 & artist.hotness<0.65),]\n",
    "low_class = music[which(artist.hotness<0.3),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dummy columns\n",
    "library(dummies)\n",
    "Key = dummy(music$key)\n",
    "Mode = dummy(music$mode)\n",
    "g_Term = dummy(music$grouped_terms)\n",
    "t_Sig = dummy(music$time_signature)\n",
    "Decade = dummy(music$decade)\n",
    "Label = dummy(music$artists.grouped)\n",
    "music = cbind(music, Key,Mode,g_Term,t_Sig,Label)\n",
    "model_columns2 = c(\"Songs\",\"artist.hotness\",\"duration\",\"start_of_fade_out\",\"end_of_fade_in\",\n",
    "                   \"loudness\", \"tempo\",  \"key0\" ,\"key1\",\"key2\",\"key3\",\"key4\",\"key5\",\"key6\",\"key7\",\n",
    "                   \"key8\",\"key9\",\"key10\",\"key11\",\"mode0\",\"mode1\",\"grouped_termschristian\",\"grouped_termsclassical\",\n",
    "                   \"grouped_termscountry\",\"grouped_termselectronic\",\"grouped_termship hop\",  \n",
    "                   \"grouped_termsjazz\",   \"grouped_termslatin\",  \"grouped_termsmetal\", \n",
    "                   \"grouped_termspop\",    \"grouped_termspunk\",   \"grouped_termsR&B\",    \"grouped_termsrock\",  \n",
    "                   \"grouped_termsspoken\",\"grouped_termsworld\",\"time_signature0\",   \"time_signature1\",  \n",
    "                   \"time_signature3\",   \"time_signature4\",   \"time_signature5\",    \"time_signature7\",  \n",
    "                   \"artists.groupedlow\" ,\"artists.groupedmedium\",\"artists.groupedhigh\" , \"song.hotness\")\n",
    "music_model = music[,model_columns2]\n",
    "\n",
    "write.csv(music_model,'/Users/AriaChen/Desktop/Columbia/E4650 BA/Group Project/music_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##some plots\n",
    "\n",
    "#song hotness against artist hotness\n",
    "plot(new_music$song.hotness~new_music$artist.hotness,xlab='Artist Hotness',ylab='Song Hotness')\n",
    "abline(v=0.3,col='red',lty=4,lwd=2)\n",
    "abline(v=0.65,col='red',lty=4,lwd=2)\n",
    "\n",
    "#distribution of song hotness by artist\n",
    "plot(density(high_class$song.hotness),type = \"l\", col = \"Green\",xlim = c(0,1.2), ylim=c(0,4),xlab='Song Hotness',\n",
    "     ylab = \"Density\", main = 'Song Hotness Distrubution by Artist Hotness')\n",
    "lines(density(low_class$song.hotness),type = \"l\", col = \"red\")\n",
    "lines(density(medium_class$song.hotness),type = \"l\", col = \"blue\")\n",
    "legend(0.45,4,legend=c(\"Low: Artist.Hotness<0.3\", \"Medium: 0.2<=Artist Hotness<0.65\", \n",
    "                          \"High: Artist.Hotness>=0.65\"),bty='n', col=c(\"red\", \"blue\", \"green\"), lty=1:1.5, cex=0.8 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d93e9e6f29f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "mm=read.csv(\"/Users/AriaChen/Desktop/Columbia/E4650 BA/Group Project/music_for_model.csv\")\n",
    "head(mm)\n",
    "set.seed(1)\n",
    "##finding optimal k\n",
    "wss=rep(0,20)\n",
    "for (i in 1:20) wss[i]<-kmeans(mm[,4:42],centers=i,nstart=100)$tot.withinss\n",
    "plot(1:20,wss,type=\"b\",xlab=\"K\",ylab= \"WSS\")\n",
    "##k=6\n",
    "grpmm<-kmeans(mm[,4:42],centers=6,nstart=80)\n",
    "grpmm\n",
    "## plot cluster\n",
    "plot(mm$song.hotness,mm$artist.hotness,col=grpmm$cluster)\n",
    "plot(mm$song.hotness,mm$artist.hotness,col=grpmm$cluster,pch=grpmm$cluster)\n",
    "\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==1)],mm$song.hotness[which(grpmm$cluster==1)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==1)]~mm$artist.hotness[which(grpmm$cluster==1)]),col='red')\n",
    "cor(mm$song.hotness[which(grpmm$cluster==1)],mm$artist.hotness[which(grpmm$cluster==1)])\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==2)],mm$song.hotness[which(grpmm$cluster==2)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==2)]~mm$artist.hotness[which(grpmm$cluster==2)]),col='red')\n",
    "cor(mm$song.hotness[which(grpmm$cluster==2)],mm$artist.hotness[which(grpmm$cluster==2)])\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==3)],mm$song.hotness[which(grpmm$cluster==3)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==3)]~mm$artist.hotness[which(grpmm$cluster==3)]),col='red')\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==3)],mm$song.hotness[which(grpmm$cluster==3)])\n",
    "\n",
    "cor(mm$song.hotness[which(grpmm$cluster==3)],mm$artist.hotness[which(grpmm$cluster==3)])\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==4)],mm$song.hotness[which(grpmm$cluster==4)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==4)]~mm$artist.hotness[which(grpmm$cluster==4)]),col='red')\n",
    "cor(mm$song.hotness[which(grpmm$cluster==4)],mm$artist.hotness[which(grpmm$cluster==4)])\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==5)],mm$song.hotness[which(grpmm$cluster==5)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==5)]~mm$artist.hotness[which(grpmm$cluster==5)]),col='red')\n",
    "cor(mm$song.hotness[which(grpmm$cluster==5)],mm$artist.hotness[which(grpmm$cluster==5)])\n",
    "\n",
    "plot(mm$artist.hotness[which(grpmm$cluster==6)],mm$song.hotness[which(grpmm$cluster==6)])\n",
    "abline(lm(mm$song.hotness[which(grpmm$cluster==6)]~mm$artist.hotness[which(grpmm$cluster==6)]),col='red')\n",
    "cor(mm$song.hotness[which(grpmm$cluster==6)],mm$artist.hotness[which(grpmm$cluster==6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
